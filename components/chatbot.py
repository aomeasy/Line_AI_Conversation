import requests
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import re
from utils.config import CHAT_API_URL, CHAT_MODEL

class ChatBot:
    """
    AI Chatbot р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Кр╣Ир╕зр╕вр╣Ар╕лр╕ер╕╖р╕н Admin р╣Бр╕ер╕░р╕Хр╕нр╕Ър╕Др╕│р╕Цр╕▓р╕бр╕ер╕╣р╕Бр╕Др╣Йр╕▓
    
    р╕Др╕зр╕▓р╕бр╕кр╕▓р╕бр╕▓р╕гр╕Ц:
    1. р╕Хр╕нр╕Ър╕Др╕│р╕Цр╕▓р╕бр╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Бр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓
    2. р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Бр╕ер╕░р╕кр╕гр╕╕р╕Ыр╕Вр╣Йр╕нр╕бр╕╣р╕е
    3. р╣Бр╕Щр╕░р╕Щр╕│р╕Бр╕▓р╕гр╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╕Ър╕гр╕┤р╕Бр╕▓р╕г
    4. р╕Кр╣Ир╕зр╕вр╕Хр╕нр╕Ър╕ер╕╣р╕Бр╕Др╣Йр╕▓р╕нр╕▒р╕Хр╣Вр╕Щр╕бр╕▒р╕Хр╕┤ (р╣Гр╕Щр╕нр╕Щр╕▓р╕Др╕Х)
    """
    
    def __init__(self):
        self.model_url = CHAT_API_URL
        self.model_name = CHAT_MODEL
        self.system_prompt = """р╕Др╕╕р╕Ур╕Др╕╖р╕н AI Assistant р╕кр╕│р╕лр╕гр╕▒р╕Ър╕гр╕░р╕Ър╕Ър╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓ LINE OA 

р╕Др╕╕р╕Ур╕бр╕╡р╕Др╕зр╕▓р╕бр╕кр╕▓р╕бр╕▓р╕гр╕Цр╣Гр╕Щр╕Бр╕▓р╕г:
1. р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓
2. р╕кр╕гр╕╕р╕Ыр╕кр╕Цр╕┤р╕Хр╕┤р╣Бр╕ер╕░р╣Бр╕Щр╕зр╣Вр╕Щр╣Йр╕б
3. р╣Гр╕лр╣Йр╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╣Гр╕Щр╕Бр╕▓р╕гр╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╕Ър╕гр╕┤р╕Бр╕▓р╕г
4. р╕Хр╕нр╕Ър╕Др╕│р╕Цр╕▓р╕бр╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Бр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕е

р╕Бр╕гр╕╕р╕Ур╕▓р╕Хр╕нр╕Ър╣Ар╕Ыр╣Зр╕Щр╕ар╕▓р╕йр╕▓р╣Др╕Чр╕вр╕Чр╕╡р╣Ир╣Ар╕Ыр╣Зр╕Щр╕бр╕┤р╕Хр╕г р╕кр╕╕р╕ар╕▓р╕Ю р╣Бр╕ер╕░р╣Гр╕лр╣Йр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Чр╕╡р╣Ир╣Ар╕Ыр╣Зр╕Щр╕Ыр╕гр╕░р╣Вр╕вр╕Кр╕Щр╣М
р╕лр╕▓р╕Бр╣Др╕бр╣Ир╕бр╕╡р╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕н р╣Гр╕лр╣Йр╣Бр╕Ир╣Йр╕Зр╕Кр╕▒р╕Фр╣Ар╕Ир╕Щ р╣Бр╕ер╕░р╣Бр╕Щр╕░р╕Щр╕│р╕Чр╕▓р╕Зр╣Ар╕ер╕╖р╕нр╕Бр╕нр╕╖р╣Ир╕Щ"""
    
    def get_response(self, user_message: str, context: Optional[List[Dict]] = None) -> str:
        """р╣Др╕Фр╣Йр╕Др╕│р╕Хр╕нр╕Ър╕Ир╕▓р╕Б AI"""
        try:
            # р╣Ар╕Хр╕гр╕╡р╕вр╕б context р╕Ир╕▓р╕Бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓
            context_text = self._prepare_context(context) if context else ""
            
            # р╕кр╕гр╣Йр╕▓р╕З prompt
            full_prompt = f"""{self.system_prompt}

Context р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓ (10 р╕гр╕▓р╕вр╕Бр╕▓р╕гр╕ер╣Ир╕▓р╕кр╕╕р╕Ф):
{context_text}

р╕Др╕│р╕Цр╕▓р╕бр╕Ир╕▓р╕Б Admin: {user_message}

р╕Др╕│р╕Хр╕нр╕Ъ:"""

            # р╣Ар╕гр╕╡р╕вр╕Б AI API
            response = requests.post(
                self.model_url,
                json={
                    "model": self.model_name,
                    "prompt": full_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "max_tokens": 1000
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                ai_response = result.get('response', '').strip()
                
                # р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╣Бр╕ер╕░р╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╕Др╕│р╕Хр╕нр╕Ъ
                if ai_response:
                    return self._post_process_response(ai_response, user_message)
                else:
                    return "р╕Вр╕нр╕нр╕ар╕▒р╕в р╣Др╕бр╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╕кр╕гр╣Йр╕▓р╕Зр╕Др╕│р╕Хр╕нр╕Ър╣Др╕Фр╣Йр╣Гр╕Щр╕Вр╕Ур╕░р╕Щр╕╡р╣Й"
            
            else:
                return f"р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╣Ар╕Кр╕╖р╣Ир╕нр╕бр╕Хр╣Ир╕н AI (Status: {response.status_code})"
                
        except requests.exceptions.Timeout:
            return "р╕Бр╕▓р╕гр╣Ар╕Кр╕╖р╣Ир╕нр╕бр╕Хр╣Ир╕н AI р╕лр╕бр╕Фр╣Ар╕зр╕ер╕▓ р╕Бр╕гр╕╕р╕Ур╕▓р╕ер╕нр╕Зр╣Гр╕лр╕бр╣Ир╕нр╕╡р╕Бр╕Др╕гр╕▒р╣Йр╕З"
        except requests.exceptions.ConnectionError:
            return "р╣Др╕бр╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╣Ар╕Кр╕╖р╣Ир╕нр╕бр╕Хр╣Ир╕нр╕Бр╕▒р╕Ъ AI р╣Др╕Фр╣Й р╕Бр╕гр╕╕р╕Ур╕▓р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Бр╕▓р╕гр╕Хр╕▒р╣Йр╕Зр╕Др╣Ир╕▓"
        except Exception as e:
            return f"р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Др╕бр╣Ир╕Др╕▓р╕Фр╕Др╕┤р╕Ф: {str(e)}"
    
    def _prepare_context(self, context: List[Dict]) -> str:
        """р╣Ар╕Хр╕гр╕╡р╕вр╕б context р╕кр╕│р╕лр╕гр╕▒р╕Ъ AI"""
        if not context:
            return ""
        
        context_lines = []
        for i, conv in enumerate(context[:10], 1):  # р╣Ар╕нр╕▓р╣Бр╕Др╣И 10 р╕гр╕▓р╕вр╕Бр╕▓р╕гр╕ер╣Ир╕▓р╕кр╕╕р╕Ф
            timestamp = conv.get('timestamp', 'Unknown')
            user_id = conv.get('user_id', 'Unknown')
            sender = conv.get('sender_type', 'Unknown')
            message = conv.get('message', '')[:100]  # р╕Ир╕│р╕Бр╕▒р╕Фр╕Др╕зр╕▓р╕бр╕вр╕▓р╕з
            sentiment = conv.get('sentiment', 'Unknown')
            
            context_lines.append(
                f"{i}. [{timestamp}] {sender} ({user_id}): {message} [р╕Др╕зр╕▓р╕бр╕гр╕╣р╣Йр╕кр╕╢р╕Б: {sentiment}]"
            )
        
        return "\n".join(context_lines)
    
    def _post_process_response(self, response: str, original_question: str) -> str:
        """р╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╕Др╕│р╕Хр╕нр╕Ър╕Бр╣Ир╕нр╕Щр╕кр╣Ир╕Зр╣Гр╕лр╣Йр╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й"""
        # р╕ер╕Ър╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Чр╕╡р╣Ир╣Др╕бр╣Ир╕Ир╕│р╣Ар╕Ыр╣Зр╕Щ
        response = re.sub(r'^\s*р╕Др╕│р╕Хр╕нр╕Ъ:\s*', '', response, flags=re.MULTILINE)
        response = re.sub(r'^\s*р╕Хр╕нр╕Ъ:\s*', '', response, flags=re.MULTILINE)
        
        # р╣Ар╕Юр╕┤р╣Ир╕бр╕Др╕зр╕▓р╕бр╕кр╕╕р╕ар╕▓р╕Ю
        if not response.startswith(('р╕кр╕зр╕▒р╕кр╕Фр╕╡', 'р╕Вр╕нр╕Ър╕Др╕╕р╕У', 'р╕Хр╕▓р╕б')):
            response = f"р╕Хр╕▓р╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Чр╕╡р╣Ир╕бр╕╡ {response}"
        
        # р╕Ир╕│р╕Бр╕▒р╕Фр╕Др╕зр╕▓р╕бр╕вр╕▓р╕з
        if len(response) > 2000:
            response = response[:1950] + "...\n\n(р╕Др╕│р╕Хр╕нр╕Ър╕Цр╕╣р╕Бр╕Хр╕▒р╕Фр╕Чр╕нр╕Щр╣Ар╕Щр╕╖р╣Ир╕нр╕Зр╕Ир╕▓р╕Бр╕вр╕▓р╕зр╣Ар╕Бр╕┤р╕Щр╣Др╕Ы)"
        
        return response.strip()
    
    def analyze_question_intent(self, question: str) -> Dict[str, Any]:
        """р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Ар╕Ир╕Хр╕Щр╕▓р╕Вр╕нр╕Зр╕Др╕│р╕Цр╕▓р╕б"""
        question_lower = question.lower()
        
        intents = {
            'analytics': ['р╕кр╕Цр╕┤р╕Хр╕┤', 'р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М', 'р╕Ир╕│р╕Щр╕зр╕Щ', 'р╕Бр╕гр╕▓р╕Я', 'р╕Вр╣Йр╕нр╕бр╕╣р╕е', 'р╕гр╕▓р╕вр╕Зр╕▓р╕Щ'],
            'sentiment': ['р╕Др╕зр╕▓р╕бр╕гр╕╣р╣Йр╕кр╕╢р╕Б', 'р╕Юр╕нр╣Гр╕И', 'р╣Др╕бр╣Ир╕Юр╕нр╣Гр╕И', 'р╣Вр╕Бр╕гр╕Ш', 'р╕Фр╕╡р╣Гр╕И', 'sentiment'],
            'topics': ['р╕лр╕▒р╕зр╕Вр╣Йр╕н', 'р╣Ар╕гр╕╖р╣Ир╕нр╕З', 'р╕Ыр╕▒р╕Нр╕лр╕▓', 'topic', 'р╕гр╣Йр╕нр╕Зр╣Ар╕гр╕╡р╕вр╕Щ'],
            'performance': ['р╕Ыр╕гр╕░р╕кр╕┤р╕Чр╕Шр╕┤р╕ар╕▓р╕Ю', 'р╣Ар╕гр╣Зр╕з', 'р╕Кр╣Йр╕▓', 'р╕Хр╕нр╕Ър╕Бр╕ер╕▒р╕Ъ', 'response time'],
            'suggestions': ['р╣Бр╕Щр╕░р╕Щр╕│', 'р╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕З', 'р╕Юр╕▒р╕Тр╕Щр╕▓', 'р╕Кр╣Ир╕зр╕в', 'р╕Др╕зр╕г']
        }
        
        detected_intents = []
        for intent, keywords in intents.items():
            score = sum(1 for keyword in keywords if keyword in question_lower)
            if score > 0:
                detected_intents.append({
                    'intent': intent,
                    'confidence': score / len(keywords),
                    'keywords_found': score
                })
        
        # р╣Ар╕гр╕╡р╕вр╕Зр╕Хр╕▓р╕б confidence
        detected_intents.sort(key=lambda x: x['confidence'], reverse=True)
        
        return {
            'question': question,
            'intents': detected_intents[:3],  # р╣Ар╕нр╕▓р╣Бр╕Др╣И 3 р╕нр╕▒р╕Щр╣Бр╕гр╕Б
            'primary_intent': detected_intents[0]['intent'] if detected_intents else 'general'
        }
    
    def generate_suggested_responses(self, customer_message: str, 
                                   context: Optional[List[Dict]] = None) -> List[Dict[str, Any]]:
        """
        р╕кр╕гр╣Йр╕▓р╕Зр╕Др╕│р╕Хр╕нр╕Ър╕Чр╕╡р╣Ир╣Бр╕Щр╕░р╕Щр╕│р╕кр╕│р╕лр╕гр╕▒р╕Ър╣Ар╕Ир╣Йр╕▓р╕лр╕Щр╣Йр╕▓р╕Чр╕╡р╣И
        р╣Гр╕Кр╣Йр╕кр╕│р╕лр╕гр╕▒р╕Ър╕Кр╣Ир╕зр╕вр╣Ар╕Ир╣Йр╕▓р╕лр╕Щр╣Йр╕▓р╕Чр╕╡р╣Ир╕Хр╕нр╕Ър╕ер╕╣р╕Бр╕Др╣Йр╕▓р╣Др╕Фр╣Йр╣Ар╕гр╣Зр╕зр╕Вр╕╢р╣Йр╕Щ
        """
        try:
            # р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Ыр╕гр╕░р╣Ар╕ар╕Чр╕Вр╕нр╕Зр╕Др╕│р╕Цр╕▓р╕бр╕ер╕╣р╕Бр╕Др╣Йр╕▓
            message_lower = customer_message.lower()
            
            suggested_responses = []
            
            # р╕Др╕│р╕Хр╕нр╕Ър╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕▓р╕гр╕Чр╕▒р╕Бр╕Чр╕▓р╕в
            if any(greeting in message_lower for greeting in ['р╕кр╕зр╕▒р╕кр╕Фр╕╡', 'р╕з', 'hello', 'hi']):
                suggested_responses.append({
                    'type': 'greeting',
                    'response': 'р╕кр╕зр╕▒р╕кр╕Фр╕╡р╕Др╣Ир╕░ р╕вр╕┤р╕Щр╕Фр╕╡р╣Гр╕лр╣Йр╕Ър╕гр╕┤р╕Бр╕▓р╕г ЁЯЩП р╕бр╕╡р╕нр╕░р╣Др╕гр╣Гр╕лр╣Йр╕Кр╣Ир╕зр╕вр╣Ар╕лр╕ер╕╖р╕нр╣Др╕лр╕бр╕Др╕░?',
                    'confidence': 0.9
                })
            
            # р╕Др╕│р╕Хр╕нр╕Ър╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕▓р╕гр╕кр╕нр╕Ър╕Цр╕▓р╕бр╕гр╕▓р╕Др╕▓
            elif any(price in message_lower for price in ['р╕гр╕▓р╕Др╕▓', 'р╣Ар╕Чр╣Ир╕▓р╣Др╕лр╕гр╣И', 'price', 'cost']):
                suggested_responses.extend([
                    {
                        'type': 'price_inquiry',
                        'response': 'р╕кр╕│р╕лр╕гр╕▒р╕Ър╕гр╕▓р╕Др╕▓р╕кр╕┤р╕Щр╕Др╣Йр╕▓р╕Др╣Ир╕░ р╕Вр╕нр╣Гр╕лр╣Йр╕кр╣Ир╕Зр╕гр╕╣р╕Ыр╕лр╕гр╕╖р╕нр╕Кр╕╖р╣Ир╕нр╕кр╕┤р╕Щр╕Др╣Йр╕▓р╕бр╕▓р╣Гр╕лр╣Йр╕лр╕Щр╣Ир╕нр╕вр╕Др╣Ир╕░ р╕Ир╕░р╣Др╕Фр╣Йр╣Ар╕Кр╣Зр╕Др╕гр╕▓р╕Др╕▓р╣Гр╕лр╣Йр╕Цр╕╣р╕Бр╕Хр╣Йр╕нр╕З ЁЯТ░',
                        'confidence': 0.85
                    },
                    {
                        'type': 'price_inquiry',
                        'response': 'р╕гр╕▓р╕Др╕▓р╕кр╕┤р╕Щр╕Др╣Йр╕▓р╕Ир╕░р╣Бр╕Хр╕Бр╕Хр╣Ир╕▓р╕Зр╕Бр╕▒р╕Щр╣Др╕Ыр╕Хр╕▓р╕бр╣Бр╕Хр╣Ир╕ер╕░р╕гр╕╕р╣Ир╕Щр╕Др╣Ир╕░ р╕Вр╕нр╕гр╕Ър╕Бр╕зр╕Щр╕кр╣Ир╕Зр╕гр╕▓р╕вр╕ер╕░р╣Ар╕нр╕╡р╕вр╕Фр╕кр╕┤р╕Щр╕Др╣Йр╕▓р╕Чр╕╡р╣Ир╕кр╕Щр╣Гр╕Ир╕бр╕▓р╕Фр╣Йр╕зр╕вр╕Щр╕░р╕Др╕░',
                        'confidence': 0.8
                    }
                ])
            
            # р╕Др╕│р╕Хр╕нр╕Ър╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕▓р╕гр╕кр╕нр╕Ър╕Цр╕▓р╕бр╕Бр╕▓р╕гр╕Ир╕▒р╕Фр╕кр╣Ир╕З
            elif any(shipping in message_lower for shipping in ['р╕Ир╕▒р╕Фр╕кр╣Ир╕З', 'р╕кр╣Ир╕З', 'delivery', 'ship']):
                suggested_responses.extend([
                    {
                        'type': 'shipping',
                        'response': 'р╕Бр╕▓р╕гр╕Ир╕▒р╕Фр╕кр╣Ир╕Зр╣Гр╕Кр╣Йр╣Ар╕зр╕ер╕▓ 2-3 р╕зр╕▒р╕Щр╕Чр╕│р╕Бр╕▓р╕гр╕Др╣Ир╕░ р╕лр╕▓р╕Бр╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕гр╣Ар╕гр╣Ир╕Зр╕Фр╣Ир╕зр╕Щр╕кр╕▓р╕бр╕▓р╕гр╕Цр╣Ар╕ер╕╖р╕нр╕Б EMS р╣Др╕Фр╣Й ЁЯЪЪ',
                        'confidence': 0.9
                    },
                    {
                        'type': 'shipping',
                        'response': 'р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Др╣Ир╕▓р╕Ир╕▒р╕Фр╕кр╣Ир╕Зр╕Др╣Ир╕░ р╕ар╕▓р╕вр╣Гр╕Щр╕Бр╕гр╕╕р╕Зр╣Ар╕Чр╕Ю 50 р╕Ър╕▓р╕Ч р╕Хр╣Ир╕▓р╕Зр╕Ир╕▒р╕Зр╕лр╕зр╕▒р╕Ф 80 р╕Ър╕▓р╕Ч (Kerry) р╣Бр╕ер╕░ 120 р╕Ър╕▓р╕Ч (EMS)',
                        'confidence': 0.85
                    }
                ])
            
            # р╕Др╕│р╕Хр╕нр╕Ър╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕▓р╕гр╕гр╣Йр╕нр╕Зр╣Ар╕гр╕╡р╕вр╕Щ
            elif any(complaint in message_lower for complaint in ['р╕гр╣Йр╕нр╕Зр╣Ар╕гр╕╡р╕вр╕Щ', 'р╕Ыр╕▒р╕Нр╕лр╕▓', 'р╣Ар╕кр╕╡р╕в', 'р╣Бр╕вр╣И', 'р╣Др╕бр╣Ир╕Фр╕╡']):
                suggested_responses.extend([
                    {
                        'type': 'complaint',
                        'response': 'р╕Вр╕нр╕нр╕ар╕▒р╕вр╣Гр╕Щр╕Др╕зр╕▓р╕бр╣Др╕бр╣Ир╕кр╕░р╕Фр╕зр╕Бр╕Др╣Ир╕░ ЁЯЩП р╕Вр╕нр╕гр╕Ър╕Бр╕зр╕Щр╕кр╣Ир╕Зр╕гр╕╣р╕Ыр╕ар╕▓р╕Юр╕лр╕гр╕╖р╕нр╕гр╕▓р╕вр╕ер╕░р╣Ар╕нр╕╡р╕вр╕Фр╕Ыр╕▒р╕Нр╕лр╕▓р╕бр╕▓р╣Гр╕лр╣Йр╕Фр╕╣р╕лр╕Щр╣Ир╕нр╕вр╕Др╣Ир╕░ р╕Ир╕░р╣Др╕Фр╣Йр╕Кр╣Ир╕зр╕вр╣Бр╕Бр╣Йр╣Др╕Вр╣Гр╕лр╣Й',
                        'confidence': 0.9
                    },
                    {
                        'type': 'complaint',
                        'response': 'р╣Ар╕кр╕╡р╕вр╣Гр╕Ир╕Фр╣Йр╕зр╕вр╕Щр╕░р╕Др╕░р╕Чр╕╡р╣Ир╕бр╕╡р╕Ыр╕▒р╕Нр╕лр╕▓ ЁЯШФ р╕Вр╕нр╕Фр╕╣р╕гр╕▓р╕вр╕ер╕░р╣Ар╕нр╕╡р╕вр╕Фр╕Ыр╕▒р╕Нр╕лр╕▓р╕лр╕Щр╣Ир╕нр╕вр╕Др╣Ир╕░ р╣Ар╕гр╕▓р╕Ир╕░р╕гр╕╡р╕Ър╣Бр╕Бр╣Йр╣Др╕Вр╣Гр╕лр╣Йр╣Ар╕гр╣Зр╕зр╕Чр╕╡р╣Ир╕кр╕╕р╕Ф',
                        'confidence': 0.85
                    }
                ])
            
            # р╕Др╕│р╕Хр╕нр╕Ър╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕▓р╕гр╕Вр╕нр╕Ър╕Др╕╕р╕У
            elif any(thanks in message_lower for thanks in ['р╕Вр╕нр╕Ър╕Др╕╕р╕У', 'thank', 'р╕Вр╕нр╕Ър╣Гр╕И']):
                suggested_responses.extend([
                    {
                        'type': 'thanks',
                        'response': 'р╕вр╕┤р╕Щр╕Фр╕╡р╕Др╣Ир╕░ р╕лр╕▓р╕Бр╕бр╕╡р╕нр╕░р╣Др╕гр╕нр╕╡р╕Бр╕кр╕▓р╕бр╕▓р╕гр╕Цр╕кр╕нр╕Ър╕Цр╕▓р╕бр╕бр╕▓р╣Др╕Фр╣Йр╣Ар╕кр╕бр╕нр╕Щр╕░р╕Др╕░ ЁЯШК',
                        'confidence': 0.95
                    },
                    {
                        'type': 'thanks',
                        'response': 'р╣Др╕бр╣Ир╣Ар╕Ыр╣Зр╕Щр╣Др╕гр╕Др╣Ир╕░ р╕Вр╕нр╕Ър╕Др╕╕р╕Ур╕Чр╕╡р╣Ир╣Гр╕Кр╣Йр╕Ър╕гр╕┤р╕Бр╕▓р╕гр╕Фр╣Йр╕зр╕вр╕Др╣Ир╕░ ЁЯЩП',
                        'confidence': 0.9
                    }
                ])
            
            # р╕Др╕│р╕Хр╕нр╕Ър╕Чр╕▒р╣Ир╕зр╣Др╕Ы
            else:
                suggested_responses.append({
                    'type': 'general',
                    'response': 'р╕кр╕зр╕▒р╕кр╕Фр╕╡р╕Др╣Ир╕░ р╕Вр╕нр╕Фр╕╣р╕гр╕▓р╕вр╕ер╕░р╣Ар╕нр╕╡р╕вр╕Фр╕лр╕Щр╣Ир╕нр╕вр╕Щр╕░р╕Др╕░ р╕Ир╕░р╣Др╕Фр╣Йр╕Хр╕нр╕Ър╕Др╕│р╕Цр╕▓р╕бр╣Гр╕лр╣Йр╕Цр╕╣р╕Бр╕Хр╣Йр╕нр╕Зр╕Др╣Ир╕░ ЁЯдЧ',
                    'confidence': 0.6
                })
            
            # р╣Ар╕гр╕╡р╕вр╕Зр╕Хр╕▓р╕б confidence
            suggested_responses.sort(key=lambda x: x['confidence'], reverse=True)
            
            return suggested_responses[:3]  # р╕Др╕╖р╕Щр╕Др╣Ир╕▓р╣Бр╕Др╣И 3 р╕Хр╕▒р╕зр╣Ар╕ер╕╖р╕нр╕Б
            
        except Exception as e:
            print(f"Error generating suggested responses: {str(e)}")
            return []
    
    def generate_auto_response(self, customer_message: str, 
                             context: Optional[List[Dict]] = None,
                             confidence_threshold: float = 0.8) -> Optional[Dict[str, Any]]:
        """
        р╕кр╕гр╣Йр╕▓р╕Зр╕Др╕│р╕Хр╕нр╕Ър╕нр╕▒р╕Хр╣Вр╕Щр╕бр╕▒р╕Хр╕┤р╕кр╕│р╕лр╕гр╕▒р╕Ър╕ер╕╣р╕Бр╕Др╣Йр╕▓
        р╣Гр╕Кр╣Йр╣Ар╕бр╕╖р╣Ир╕нр╣Ар╕Ыр╕┤р╕Фр╣Гр╕Кр╣Йр╕Зр╕▓р╕Щ auto_response р╣Гр╕Щр╕Бр╕▓р╕гр╕Хр╕▒р╣Йр╕Зр╕Др╣Ир╕▓
        """
        try:
            suggested = self.generate_suggested_responses(customer_message, context)
            
            if suggested and suggested[0]['confidence'] >= confidence_threshold:
                # р╣Гр╕Кр╣Й AI р╣Ар╕Юр╕╖р╣Ир╕нр╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╕Др╕│р╕Хр╕нр╕Ър╣Гр╕лр╣Йр╣Ар╕лр╕бр╕▓р╕░р╕кр╕бр╕Бр╕▒р╕Ъ context
                enhanced_response = self._enhance_response_with_context(
                    suggested[0]['response'], 
                    customer_message, 
                    context
                )
                
                return {
                    'response': enhanced_response,
                    'confidence': suggested[0]['confidence'],
                    'type': suggested[0]['type'],
                    'is_auto': True,
                    'timestamp': datetime.now()
                }
            
            return None  # р╕Др╕зр╕▓р╕бр╕бр╕▒р╣Ир╕Щр╣Гр╕Ир╣Др╕бр╣Ир╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕нр╕кр╕│р╕лр╕гр╕▒р╕Ър╕Хр╕нр╕Ър╕нр╕▒р╕Хр╣Вр╕Щр╕бр╕▒р╕Хр╕┤
            
        except Exception as e:
            print(f"Error generating auto response: {str(e)}")
            return None
    
    def _enhance_response_with_context(self, base_response: str, 
                                     customer_message: str,
                                     context: Optional[List[Dict]]) -> str:
        """р╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╕Др╕│р╕Хр╕нр╕Ър╕Фр╣Йр╕зр╕в AI р╣Вр╕Фр╕вр╣Гр╕Кр╣Й context"""
        try:
            context_text = self._prepare_context(context) if context else ""
            
            enhance_prompt = f"""р╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╕Др╕│р╕Хр╕нр╕Ър╣Гр╕лр╣Йр╣Ар╕лр╕бр╕▓р╕░р╕кр╕бр╕Бр╕▒р╕Ър╕Ър╕гр╕┤р╕Ър╕Чр╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓:

р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕ер╕╣р╕Бр╕Др╣Йр╕▓: {customer_message}
р╕Др╕│р╕Хр╕нр╕Ър╣Ар╕гр╕┤р╣Ир╕бр╕Хр╣Йр╕Щ: {base_response}

Context р╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓:
{context_text}

р╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╕Др╕│р╕Хр╕нр╕Ър╣Гр╕лр╣Й:
1. р╣Ар╕лр╕бр╕▓р╕░р╕кр╕бр╕Бр╕▒р╕Ър╕Ър╕гр╕┤р╕Ър╕Ч
2. р╕кр╕╕р╕ар╕▓р╕Юр╣Бр╕ер╕░р╣Ар╕Ыр╣Зр╕Щр╕бр╕┤р╕Хр╕г
3. р╕Хр╕гр╕Зр╕Ыр╕гр╕░р╣Ар╕Фр╣Зр╕Щ
4. р╕кр╕▒р╣Йр╕Щр╕Бр╕гр╕░р╕Чр╕▒р╕Фр╕гр╕▒р╕Ф

р╕Др╕│р╕Хр╕нр╕Ър╕Чр╕╡р╣Ир╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╣Бр╕ер╣Йр╕з:"""
            
            response = requests.post(
                self.model_url,
                json={
                    "model": self.model_name,
                    "prompt": enhance_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.5,
                        "max_tokens": 200
                    }
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                enhanced = result.get('response', '').strip()
                return enhanced if enhanced else base_response
            else:
                return base_response
                
        except Exception as e:
            print(f"Error enhancing response: {str(e)}")
            return base_response
    
    def get_conversation_insights(self, conversation_data: List[Dict]) -> str:
        """р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Бр╕ер╕░р╣Гр╕лр╣Й insights р╕Ир╕▓р╕Бр╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓"""
        try:
            if not conversation_data:
                return "р╣Др╕бр╣Ир╕бр╕╡р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓р╣Гр╕лр╣Йр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М"
            
            # р╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╕лр╕гр╕▒р╕Ъ AI
            convo_summary = self._summarize_conversation_for_ai(conversation_data)
            
            insights_prompt = f"""р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓р╕Щр╕╡р╣Йр╣Бр╕ер╕░р╣Гр╕лр╣Й insights:

{convo_summary}

р╕Бр╕гр╕╕р╕Ур╕▓р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М:
1. р╕Др╕зр╕▓р╕бр╕гр╕╣р╣Йр╕кр╕╢р╕Бр╣Вр╕Фр╕вр╕гр╕зр╕бр╕Вр╕нр╕Зр╕ер╕╣р╕Бр╕Др╣Йр╕▓
2. р╕Ыр╕гр╕░р╣Ар╕Фр╣Зр╕Щр╕лр╕ер╕▒р╕Бр╕Чр╕╡р╣Ир╕ер╕╣р╕Бр╕Др╣Йр╕▓р╕кр╕Щр╣Гр╕И
3. р╕Ыр╕гр╕░р╕кр╕┤р╕Чр╕Шр╕┤р╕ар╕▓р╕Юр╕Бр╕▓р╕гр╕Хр╕нр╕Ър╕Бр╕ер╕▒р╕Ър╕Вр╕нр╕Зр╣Ар╕Ир╣Йр╕▓р╕лр╕Щр╣Йр╕▓р╕Чр╕╡р╣И
4. р╕Вр╣Йр╕нр╣Ар╕кр╕Щр╕нр╣Бр╕Щр╕░р╣Ар╕Юр╕╖р╣Ир╕нр╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╕Ър╕гр╕┤р╕Бр╕▓р╕г

р╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М:"""
            
            response = requests.post(
                self.model_url,
                json={
                    "model": self.model_name,
                    "prompt": insights_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "max_tokens": 500
                    }
                },
                timeout=45
            )
            
            if response.status_code == 200:
                result = response.json()
                insights = result.get('response', '').strip()
                return insights if insights else "р╣Др╕бр╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Др╕Фр╣Йр╣Гр╕Щр╕Вр╕Ур╕░р╕Щр╕╡р╣Й"
            else:
                return "р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Фр╣Гр╕Щр╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М"
                
        except Exception as e:
            print(f"Error getting insights: {str(e)}")
            return f"р╣Ар╕Бр╕┤р╕Фр╕Вр╣Йр╕нр╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Ф: {str(e)}"
    
    def _summarize_conversation_for_ai(self, conversation_data: List[Dict]) -> str:
        """р╕кр╕гр╕╕р╕Ыр╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓р╕кр╕│р╕лр╕гр╕▒р╕Ъ AI р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М"""
        lines = []
        
        for i, msg in enumerate(conversation_data[:20], 1):  # р╕Ир╕│р╕Бр╕▒р╕Фр╣Бр╕Др╣И 20 р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б
            sender = msg.get('sender_type', 'unknown')
            message = msg.get('message', '')[:150]  # р╕Ир╕│р╕Бр╕▒р╕Фр╕Др╕зр╕▓р╕бр╕вр╕▓р╕з
            timestamp = msg.get('timestamp', '')
            sentiment = msg.get('sentiment', 'neutral')
            
            lines.append(f"{i}. [{sender}] {message} (р╕Др╕зр╕▓р╕бр╕гр╕╣р╣Йр╕кр╕╢р╕Б: {sentiment})")
        
        return "\n".join(lines)
    
    def check_service_availability(self) -> Dict[str, Any]:
        """р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Др╕зр╕▓р╕бр╕Юр╕гр╣Йр╕нр╕бр╕Вр╕нр╕З AI service"""
        try:
            test_response = requests.post(
                self.model_url,
                json={
                    "model": self.model_name,
                    "prompt": "р╕кр╕зр╕▒р╕кр╕Фр╕╡",
                    "stream": False,
                    "options": {"max_tokens": 10}
                },
                timeout=10
            )
            
            if test_response.status_code == 200:
                return {
                    'available': True,
                    'status': 'online',
                    'model': self.model_name,
                    'response_time': test_response.elapsed.total_seconds()
                }
            else:
                return {
                    'available': False,
                    'status': 'error',
                    'error_code': test_response.status_code
                }
                
        except requests.exceptions.Timeout:
            return {
                'available': False,
                'status': 'timeout',
                'error': 'Service timeout'
            }
        except requests.exceptions.ConnectionError:
            return {
                'available': False,
                'status': 'connection_error',
                'error': 'Cannot connect to service'
            }
        except Exception as e:
            return {
                'available': False,
                'status': 'error',
                'error': str(e)
            }
    
    def get_help_suggestions(self, user_type: str = 'admin') -> List[str]:
        """р╣Гр╕лр╣Йр╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕Др╕│р╕Цр╕▓р╕бр╕Чр╕╡р╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╕Цр╕▓р╕бр╣Др╕Фр╣Й"""
        if user_type == 'admin':
            return [
                "ЁЯУК р╕кр╕Цр╕┤р╕Хр╕┤р╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓р╕зр╕▒р╕Щр╕Щр╕╡р╣Йр╣Ар╕Ыр╣Зр╕Щр╕нр╕вр╣Ир╕▓р╕Зр╣Др╕г?",
                "ЁЯШК р╕Др╕зр╕▓р╕бр╕гр╕╣р╣Йр╕кр╕╢р╕Бр╕Вр╕нр╕Зр╕ер╕╣р╕Бр╕Др╣Йр╕▓р╣Вр╕Фр╕вр╕гр╕зр╕бр╣Ар╕Ыр╣Зр╕Щр╕нр╕вр╣Ир╕▓р╕Зр╣Др╕г?",
                "ЁЯП╖я╕П р╕лр╕▒р╕зр╕Вр╣Йр╕нр╣Др╕лр╕Щр╕Чр╕╡р╣Ир╕ер╕╣р╕Бр╕Др╣Йр╕▓р╕кр╕Щр╕Чр╕Щр╕▓р╕Бр╕▒р╕Щр╕Ър╣Ир╕нр╕вр╕Чр╕╡р╣Ир╕кр╕╕р╕Ф?",
                "тП▒я╕П р╣Ар╕зр╕ер╕▓р╕Хр╕нр╕Ър╕Бр╕ер╕▒р╕Ър╣Ар╕Йр╕ер╕╡р╣Ир╕вр╣Ар╕Ыр╣Зр╕Щр╣Ар╕Чр╣Ир╕▓р╣Др╕лр╕гр╣И?",
                "ЁЯТб р╕бр╕╡р╕Вр╣Йр╕нр╣Ар╕кр╕Щр╕нр╣Бр╕Щр╕░р╣Гр╕Щр╕Бр╕▓р╕гр╕Ыр╕гр╕▒р╕Ър╕Ыр╕гр╕╕р╕Зр╕Ър╕гр╕┤р╕Бр╕▓р╕гр╣Др╕лр╕б?",
                "ЁЯУИ р╣Бр╕Щр╕зр╣Вр╕Щр╣Йр╕бр╕Бр╕▓р╕гр╕кр╕Щр╕Чр╕Щр╕▓р╣Гр╕Щр╕Кр╣Ир╕зр╕З 7 р╕зр╕▒р╕Щр╕Чр╕╡р╣Ир╕Ьр╣Ир╕▓р╕Щр╕бр╕▓",
                "ЁЯОп р╕Ыр╕▒р╕Нр╕лр╕▓р╕Чр╕╡р╣Ир╕Юр╕Ър╕Ър╣Ир╕нр╕вр╕Чр╕╡р╣Ир╕кр╕╕р╕Фр╕Др╕╖р╕нр╕нр╕░р╣Др╕г?",
                "ЁЯФН р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Ыр╕гр╕░р╕кр╕┤р╕Чр╕Шр╕┤р╕ар╕▓р╕Юр╕Чр╕╡р╕бр╕Зр╕▓р╕Щ"
            ]
        else:
            return [
                "ЁЯЫНя╕П р╕кр╕нр╕Ър╕Цр╕▓р╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕┤р╕Щр╕Др╣Йр╕▓",
                "ЁЯТ░ р╕кр╕нр╕Ър╕Цр╕▓р╕бр╕гр╕▓р╕Др╕▓",
                "ЁЯЪЪ р╕кр╕нр╕Ър╕Цр╕▓р╕бр╕Бр╕▓р╕гр╕Ир╕▒р╕Фр╕кр╣Ир╕З",
                "ЁЯФД р╕кр╕нр╕Ър╕Цр╕▓р╕бр╕Бр╕▓р╕гр╕Др╕╖р╕Щр╕кр╕┤р╕Щр╕Др╣Йр╕▓",
                "тЭУ р╕кр╕нр╕Ър╕Цр╕▓р╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Чр╕▒р╣Ир╕зр╣Др╕Ы"
            ]
    
    def format_response_for_display(self, response: str) -> str:
        """р╕Ир╕▒р╕Фр╕гр╕╣р╕Ыр╣Бр╕Ър╕Ър╕Др╕│р╕Хр╕нр╕Ър╣Гр╕лр╣Йр╣Бр╕кр╕Фр╕Зр╕Ьр╕ер╕Фр╕╡"""
        # р╣Бр╕Ыр╕ер╕З markdown basics
        response = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', response)
        response = re.sub(r'\*(.*?)\*', r'<em>\1</em>', response)
        
        # р╣Бр╕Ыр╕ер╕Зр╕гр╕▓р╕вр╕Бр╕▓р╕г
        response = re.sub(r'^\d+\.\s+', 'тАв ', response, flags=re.MULTILINE)
        response = re.sub(r'^-\s+', 'тАв ', response, flags=re.MULTILINE)
        
        # р╣Ар╕Юр╕┤р╣Ир╕б emoji р╕кр╕│р╕лр╕гр╕▒р╕Ър╕лр╕▒р╕зр╕Вр╣Йр╕н
        response = re.sub(r'р╕кр╕Цр╕┤р╕Хр╕┤', 'ЁЯУК р╕кр╕Цр╕┤р╕Хр╕┤', response)
        response = re.sub(r'р╕Др╕зр╕▓р╕бр╕гр╕╣р╣Йр╕кр╕╢р╕Б', 'ЁЯШК р╕Др╕зр╕▓р╕бр╕гр╕╣р╣Йр╕кр╕╢р╕Б', response)
        response = re.sub(r'р╕лр╕▒р╕зр╕Вр╣Йр╕н', 'ЁЯП╖я╕П р╕лр╕▒р╕зр╕Вр╣Йр╕н', response)
        response = re.sub(r'р╣Ар╕зр╕ер╕▓р╕Хр╕нр╕Ър╕Бр╕ер╕▒р╕Ъ', 'тП▒я╕П р╣Ар╕зр╕ер╕▓р╕Хр╕нр╕Ър╕Бр╕ер╕▒р╕Ъ', response)
        response = re.sub(r'р╕Вр╣Йр╕нр╣Ар╕кр╕Щр╕нр╣Бр╕Щр╕░', 'ЁЯТб р╕Вр╣Йр╕нр╣Ар╕кр╕Щр╕нр╣Бр╕Щр╕░', response)
        
        return response